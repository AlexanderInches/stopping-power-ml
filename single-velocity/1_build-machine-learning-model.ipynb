{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Machine Learning Model\n",
    "Determine the optimal machine learning algorithm and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mrl-mrsec/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(f\"{os.getcwd()}/../\")\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "from glob import glob\n",
    "from matminer.featurizers.function import FunctionFeaturizer\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from scipy import stats\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, RepeatedKFold, GridSearchCV\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression, Lasso, LassoLars\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from stopping_power_ml.io import load_qbox_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Dataset\n",
    "This was created by a different notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set size: 9800\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_pickle(os.path.join('data', 'random_data.pkl.gz'))\n",
    "print('Data set size:', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the initial transient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 9379\n"
     ]
    }
   ],
   "source": [
    "data.query('initial == False', inplace=True)\n",
    "print('Training set size:', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which columns are inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizers = pkl.load(open(os.path.join('..', 'featurizers.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['charge density at t=-4.00', 'charge density at t=-3.00', 'charge density at t=-2.00', 'charge density at t=-1.00', 'charge density at t=-0.50', 'charge density at t=0.00', 'charge density at t=0.50', 'charge density at t=1.00', 'charge density at t=2.00', 'AGNI projected eta=8.00e-01', 'AGNI projected eta=1.23e+00', 'AGNI projected eta=1.88e+00', 'AGNI projected eta=2.89e+00', 'AGNI projected eta=4.43e+00', 'AGNI projected eta=6.80e+00', 'AGNI projected eta=1.04e+01', 'AGNI projected eta=1.60e+01', 'ion-ion repulsion']\n"
     ]
    }
   ],
   "source": [
    "X_cols = featurizers.feature_labels()\n",
    "print(X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'force'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['frame_id', 'force', 'position', 'velocity', 'energy', 'file_id',\n",
      "       'file', 'timestep', 'displacement', 'directory',\n",
      "       'charge density at t=-4.00', 'charge density at t=-3.00',\n",
      "       'charge density at t=-2.00', 'charge density at t=-1.00',\n",
      "       'charge density at t=-0.50', 'charge density at t=0.00',\n",
      "       'charge density at t=0.50', 'charge density at t=1.00',\n",
      "       'charge density at t=2.00', 'AGNI projected eta=8.00e-01',\n",
      "       'AGNI projected eta=1.23e+00', 'AGNI projected eta=1.88e+00',\n",
      "       'AGNI projected eta=2.89e+00', 'AGNI projected eta=4.43e+00',\n",
      "       'AGNI projected eta=6.80e+00', 'AGNI projected eta=1.04e+01',\n",
      "       'AGNI projected eta=1.60e+01', 'ion-ion repulsion', 'velocity_mag',\n",
      "       'initial'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "charge density at t=-4.00     -0.102200\n",
       "charge density at t=-3.00      0.501523\n",
       "charge density at t=-2.00     -3.128533\n",
       "charge density at t=-1.00     -3.514282\n",
       "charge density at t=-0.50     -3.555807\n",
       "charge density at t=0.00      -3.539587\n",
       "charge density at t=0.50      -3.497736\n",
       "charge density at t=1.00      -3.461033\n",
       "charge density at t=2.00      -3.475489\n",
       "AGNI projected eta=8.00e-01   -0.000008\n",
       "AGNI projected eta=1.23e+00   -0.004996\n",
       "AGNI projected eta=1.88e+00   -0.055899\n",
       "AGNI projected eta=2.89e+00   -0.084698\n",
       "AGNI projected eta=4.43e+00   -0.066067\n",
       "AGNI projected eta=6.80e+00   -0.059270\n",
       "AGNI projected eta=1.04e+01   -0.057636\n",
       "AGNI projected eta=1.60e+01   -0.057636\n",
       "ion-ion repulsion              0.745193\n",
       "Name: 38121, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.columns)\n",
    "data[X_cols].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out Some ML Models\n",
    "Trying out various differentiable ML algorithms. Also, throw in some feature expansion and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Testing Routine\n",
    "What we want to know whether a model trained on the beginning of a simulation can successfully predict forces at the end of the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_first_part(model, data, max_step, X_cols=X_cols, y_col=y_col):\n",
    "    \"\"\"Train a model only using the first part of a dataset, test it\n",
    "    \n",
    "    :param model: model to be tested\n",
    "    :param data: dataset used for training\n",
    "    :param max_step: int, maximum timestep. All data before this timestep will be used for training\n",
    "    :return:\n",
    "        - train_size: Number of training points\n",
    "        - average_force: Average force \n",
    "        - trajectory: Force as a function of timestep\"\"\"\n",
    "    # Train model on all timedat before current\n",
    "    train_data = data.query('timestep <= %d'%max_step)\n",
    "    model.fit(train_data[X_cols], train_data[y_col])\n",
    "\n",
    "    # Predict on all timesteps\n",
    "    traj = model.predict(data[X_cols])\n",
    "\n",
    "    # Store results\n",
    "    return len(train_data), np.mean(traj), traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_over_time(model, data, steps=None):\n",
    "    \"\"\"Train the model on increasingly-larger amounts of data\n",
    "    \n",
    "    :param model: model to be tested\n",
    "    :param data: training/test data\n",
    "    :param steps: increments to test at. Model is trained at all entries before this timestep\n",
    "    :return: Several lists:\n",
    "        - train_size: Number of training points\n",
    "        - average_force: Average force (i.e., stopping power) \n",
    "        - trajectory: Full trajectory\n",
    "        - step: timestep\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the default steps\n",
    "    if steps is None:\n",
    "        steps = np.linspace(data['timestep'].min(), data['timestep'].max(), 31, dtype=int)[1:].tolist()\n",
    "        \n",
    "        # Add exactly half\n",
    "        start_time_step = data['timestep'].min() - 1\n",
    "        steps.append(start_time_step + len(data) // 2)\n",
    "        \n",
    "        # Add in some nice bars for plotting at \n",
    "        steps.extend(np.add(start_time_step, [250, 2500, 5000, 7000]).tolist())\n",
    "        \n",
    "        # Return the sorted value\n",
    "        steps = np.sort(steps)\n",
    "        \n",
    "        \n",
    "    # Test the models\n",
    "    results = [test_on_first_part(model, data, step) for step in steps]\n",
    "    train_size, mean_forces, trajs = zip(*results)    \n",
    "    return train_size, mean_forces, trajs, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = dict()\n",
    "def run_tests(model, name, verbose=False):\n",
    "    \"\"\"Evaluate a model, store results in test_results variable\n",
    "    \n",
    "    :param model: model to test\n",
    "    :param name: name of results to store\"\"\"\n",
    "        \n",
    "    # Increase time CV\n",
    "    step, mean_forces, traj, steps = train_over_time(model, data)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Model: %s - Stopping power after half simulation: predicted=%.2f actual=%.2f'%(name,\n",
    "                                                                                              mean_forces[int(len(mean_forces)/2)],                                                                                 data[y_col].mean()))\n",
    "        \n",
    "    # Train model on whole dataset\n",
    "    model.fit(data[X_cols], data[y_col])\n",
    "    \n",
    "    test_results[name] = {\n",
    "        'over_time': {'training_size': step, 'mean_force': mean_forces, 'traj': traj, 'step':steps},\n",
    "        'model': deepcopy(model)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a dummy model\n",
    "Get a \"non-ML\" baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DummyRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: dummy - Stopping power after half simulation: predicted=0.24 actual=0.24\n",
      "CPU times: user 391 ms, sys: 15.1 ms, total: 407 ms\n",
      "Wall time: 410 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_tests(model, 'dummy', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Bayesian Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianRidge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: bayes - Stopping power after half simulation: predicted=0.24 actual=0.24\n",
      "CPU times: user 2.18 s, sys: 198 ms, total: 2.38 s\n",
      "Wall time: 866 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_tests(model, 'bayes', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Bayesian Ridge w/ Poly Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('model', BayesianRidge())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: bayes_poly - Stopping power after half simulation: predicted=0.24 actual=0.24\n",
      "CPU times: user 37 s, sys: 2.41 s, total: 39.4 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_tests(model, 'bayes_poly', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'normalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m GridSearchCV(Lasso(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m:np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m20\u001b[39m)}, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m(model)\n",
      "File \u001b[0;32m~/venv/lib/python3.12/site-packages/numpy/__init__.py:333\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'normalize'"
     ]
    }
   ],
   "source": [
    "model = GridSearchCV(Lasso(normalize=True, max_iter=500), {'alpha':np.logspace(-7,-1,20)}, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_tests(model, 'lasso', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso+BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(Pipeline([\n",
    "    ('lasso_rfe', SelectFromModel(\n",
    "        LassoLars(normalize=True, max_iter=22, fit_intercept=False, alpha=1e-10))\n",
    "    ),\n",
    "    ('model', BayesianRidge(normalize=True))\n",
    "]), {'lasso_rfe__estimator__max_iter':range(5,30)}, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_tests(model, 'lasso+bayes', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Bayesian Ridge w/ Poly Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('lasso', LassoLars(normalize=True, max_iter=35, alpha=1e-10))\n",
    "]), {'lasso__max_iter':range(40,50,1)}, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_tests(model, 'lasso_poly', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the chosen settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_results['lasso_poly']['model'].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LASSO + Bayesian Ridge w/ Poly Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('lasso_rfe', SelectFromModel(\n",
    "        LassoLars(normalize=True, max_iter=35, alpha=1e-10))\n",
    "    ),\n",
    "    ('model', BayesianRidge(normalize=True))\n",
    "]), {'lasso_rfe__estimator__max_iter':range(40,50,1)}, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_tests(model, 'lasso+bayes_poly', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the chosen settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_results['lasso+bayes_poly']['model'].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Bayesian Ridge w/ Poly Features and PCA downselection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('pca', PCA(n_components=4)),\n",
    "    ('model', BayesianRidge(normalize=True))\n",
    "]), {'pca__n_components':range(1,31,2)}, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_tests(model, 'pca+bayes_poly', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the chosen settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_results['pca+bayes_poly']['model'].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_tests(model, 'ols', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the best algorithm\n",
    "As the force acting on a particle varies by several orders of magnitude and changes sign, I will use the Spearman's correlation coefficient to determine the optimal algorithm. Usually, I like to use MAE. Given the large range of forces, small variations in the very large forces have a greater impact on the MAE than relatively similar changes on the small forces. I could also use the MRE or fit to the log of the error, but the sign change makes those routes impractical. So, I choose the Spearman's correlation coefficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} models were tested'.format(len(test_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tests = len(test_results['ols']['over_time']['traj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_number = int(num_tests * 0.5)\n",
    "\n",
    "small_forces = np.logical_and(data['force'] > 0, data['force'] < 0.4)\n",
    "train_size = test_results['lasso']['over_time']['training_size'][experiment_number]\n",
    "print('Training set size: ', train_size)\n",
    "results = dict([\n",
    "    (name, {'force_mae': np.abs(data[y_col] - my_data['over_time']['traj'][experiment_number]).mean(),\n",
    "            'small_force_mae': np.abs(data[y_col][small_forces] - \\\n",
    "                                my_data['over_time']['traj'][experiment_number][small_forces]).mean(),\n",
    "            'force_spearman': stats.spearmanr(data[y_col],\n",
    "                                              my_data['over_time']['traj'][experiment_number])[0]})\n",
    "    for name, my_data in test_results.items()\n",
    "])\n",
    "del results['dummy']\n",
    "over_time_results = pd.DataFrame(results).T\n",
    "over_time_results.sort_values('force_spearman', ascending=False, inplace=True)\n",
    "over_time_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(range(len(over_time_results)), over_time_results['force_spearman'])\n",
    "\n",
    "ax.set_xticks(range(len(over_time_results)))\n",
    "ax.set_xticklabels(list(over_time_results.index), fontsize=14, rotation=-45);\n",
    "\n",
    "ax.set_ylim(0.9, 1)\n",
    "ax.set_ylabel('Spearman Correlation', fontsize=18)\n",
    "ax.set_xlabel('Algorithm', fontsize=18)\n",
    "\n",
    "fig.set_size_inches(8, 5)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the tradeoff between the spearman $\\rho$ and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, gridspec_kw={'width_ratios':[1,1.4]})\n",
    "\n",
    "# Plot all the performances\n",
    "axs[0].scatter(over_time_results['force_spearman'],\n",
    "          over_time_results['force_mae'])\n",
    "\n",
    "axs[0].set_xlabel('Spearman Correlation')\n",
    "axs[0].set_ylabel('MAE ($E_h / a_B$)')\n",
    "axs[0].set_xlim(0.96, 1.0)\n",
    "axs[0].text(0.0, 0.99, '(a)', va='top', transform=axs[0].transAxes)\n",
    "\n",
    "# Plot the best MAE vs Best SCC\n",
    "best_mae = over_time_results['force_mae'].idxmin()\n",
    "print(f'Best MAE: {best_mae}')\n",
    "best_scc = over_time_results['force_spearman'].idxmax()\n",
    "print(f'Best SCC: {best_scc}')\n",
    "\n",
    "tddft, = axs[1].plot(data['timestep'], data['force'], 'k:', lw=1, label='none')\n",
    "tddft.set_label(None)\n",
    "axs[1].set_ylim([0.02,0.4]) # Make sure the scales stay appropriate\n",
    "axs[1].set_xlim(3990, 5300)\n",
    "\n",
    "traj = test_results[best_mae]['over_time']['traj'][experiment_number]\n",
    "axs[1].plot(data['timestep'], traj, 'r-', alpha=0.7, lw=2, label='MAE')\n",
    "\n",
    "traj = test_results[best_scc]['over_time']['traj'][experiment_number]\n",
    "axs[1].plot(data['timestep'], traj, 'b--', alpha=0.7, lw=2, label='Spearman')\n",
    "\n",
    "axs[1].set_xlabel('Timestep')\n",
    "axs[1].set_ylabel('Force ($E_h/a_B$)')\n",
    "axs[1].legend(ncol=2, loc='lower center')\n",
    "\n",
    "axs[1].text(0.0, 0.99, '(b)', va='top', transform=axs[1].transAxes)\n",
    "\n",
    "fig.set_size_inches(6, 2.5)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join('figures', 'mae-vs-spearman.png'), dpi=320)\n",
    "fig.savefig(os.path.join('figures', 'mae-vs-spearman.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding*: The model selected using spearman fits low-force data more accurately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model-comparision-results.pkl', 'wb') as fp:\n",
    "    pkl.dump(test_results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = over_time_results.index[0]\n",
    "print('Best model:', best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot just the best one\n",
    "Show the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = test_results['lasso+bayes_poly'] # This fits the data the best at large training set sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(best_results['model'], open('best_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot how well the algorithm forecasts stopping force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "for f,ax in zip([0,int(0.25*num_tests),int(0.5*num_tests),int(0.75*num_tests)],axs.flatten()):\n",
    "    \n",
    "    ax.plot(data['timestep'], data['force'], 'k--', lw=2)\n",
    "    ax.set_ylim(ax.get_ylim()) # Make sure the scales stay appropriate\n",
    "    \n",
    "    traj = best_results['over_time']['traj'][f]\n",
    "    ax.plot(data['timestep'], traj, 'r-', alpha=0.7, lw=2)\n",
    "    traj_error = np.abs(traj - data['force']).mean()\n",
    "    \n",
    "    ax.text(4200, 30, 'MAE: %.3f $E_H/a_B$'%traj_error, fontsize=18,\n",
    "           bbox=dict(edgecolor='k', facecolor='w'))\n",
    "    \n",
    "    ax.text(4000, -80, 'Training size: %d'%best_results['over_time']['training_size'][f],\n",
    "            fontsize=18,\n",
    "           bbox=dict(edgecolor='k', facecolor='w'))\n",
    "    \n",
    "    ax.plot([best_results['over_time']['step'][f],]*2, ax.get_ylim(), 'b--')\n",
    "    \n",
    "    ax.set_yscale('symlog')\n",
    "\n",
    "axs[1,0].set_xlabel('Timestep', fontsize=18)\n",
    "axs[1,1].set_xlabel('Timestep', fontsize=18)\n",
    "axs[0,0].set_ylabel('Force ($E_H/a_B$)', fontsize=18)\n",
    "axs[1,0].set_ylabel('Force ($E_H/a_B$)', fontsize=18)\n",
    "\n",
    "fig.set_size_inches(13,6)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(os.path.join('figures', 'random-trajectory-fit.png'), dpi=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "for f,ax in zip([0,int(0.25*num_tests),int(0.5*num_tests),int(0.75*num_tests)],axs.flatten()):\n",
    "    \n",
    "    ax.plot(data['timestep'], data['force'], 'k--', lw=2)\n",
    "    ax.set_ylim([0,0.4]) # Make sure the scales stay appropriate\n",
    "    ax.set_xlim(4000, 5000)\n",
    "    \n",
    "    traj = best_results['over_time']['traj'][f]\n",
    "    ax.plot(data['timestep'], traj, 'r-', alpha=0.7, lw=2)\n",
    "    traj_error = np.abs(traj - data['force']).mean()\n",
    "    \n",
    "    ax.text(0.6, 0.9, 'MAE: %.3f $E_H/a_B$'%traj_error, fontsize=18,\n",
    "           bbox=dict(edgecolor='k', facecolor='w'), transform=ax.transAxes)\n",
    "    \n",
    "    ax.text(0.6, 0, 'Training size: %d'%best_results['over_time']['training_size'][f],\n",
    "            fontsize=18, bbox=dict(edgecolor='k', facecolor='w'), transform=ax.transAxes)\n",
    "    \n",
    "    ax.plot([best_results['over_time']['step'][f],]*2, ax.get_ylim(), 'b--')\n",
    "\n",
    "axs[1,0].set_xlabel('Timestep', fontsize=18)\n",
    "axs[1,1].set_xlabel('Timestep', fontsize=18)\n",
    "axs[0,0].set_ylabel('Force ($E_H/a_B$)', fontsize=18)\n",
    "axs[1,0].set_ylabel('Force ($E_H/a_B$)', fontsize=18)\n",
    "\n",
    "fig.set_size_inches(13,6)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figure shows the fitness of the model as a function of training set size. In each frame, the model is trained on the data to the left of the blue, vertical line. The predictions of the model are shown in red and the TD-DFT result in black. After we've trained the model on half of the dataset (bottom left), the model fits the entire trajectory very well. At this point, we could stop the TD-DFT simulation and, instead, use our ML surrogate to compute the stopping power. By using the surrogate instead, we would get the same result as TD-DFT with only half of the computational expense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a learning curve\n",
    "Show the MAE as training set size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pass = data['timestep'][data['force'].idxmax()]\n",
    "second_pass = data['timestep'][(data['force'].iloc[5000:]).idxmax()]\n",
    "print('First pass is near timestep', first_pass)\n",
    "print('Second pass is near timestep', second_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "maes = [np.abs(data['force'] - t).mean() for t in test_results[best_scc]['over_time']['traj']]\n",
    "sccs = [1 - stats.spearmanr(data['force'], t)[0] for t in test_results[best_scc]['over_time']['traj']]\n",
    "\n",
    "ax.semilogy(test_results[best_scc]['over_time']['training_size'], maes, 'o-', markersize=4)\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "ax2.semilogy(test_results[best_scc]['over_time']['training_size'], sccs, 'o-', color='crimson', markersize=4)\n",
    "ax2.set_ylim(0.6, 4e-3)\n",
    "ax2.set_ylabel('1 - $ \\\\rho $')\n",
    "\n",
    "ax.annotate('1$^{st}$ Near Pass', xy=(first_pass - data['initial'].sum(), 1),\n",
    "           xytext=(3500, 8), arrowprops={'facecolor': 'k', 'width': 1.5, 'headwidth': 4})\n",
    "ax.annotate('2$^{nd}$ Near Pass', xy=(second_pass - data['initial'].sum(), 0.04),\n",
    "           xytext=(3700, 0.5), arrowprops={'facecolor': 'k', 'width': 1.5, 'headwidth': 4})\n",
    "\n",
    "ax.set_xlabel('Training Set Size')\n",
    "ax.set_ylabel('MAE ($E_H / a_B$)')\n",
    "\n",
    "fig.set_size_inches(3.5, 2.1)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join('figures', 'random-learning-curve.png'), dpi=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make it an animation\n",
    "Show the fitness improving as more training data is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_results['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.linspace(10, len(data) / 2, 200, dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(data['timestep'], data['force'], 'k--', lw=2)\n",
    "\n",
    "model.fit(data[X_cols].iloc[:10], data[y_col].iloc[:10])\n",
    "lne, = ax.plot(data['timestep'], model.predict(data[X_cols]), 'r-', alpha=0.7, lw=2)\n",
    "ax.set_ylim(ax.get_ylim())\n",
    "bar, = ax.plot([data['timestep'].iloc[:1].max(),]*2, ax.get_ylim(), 'b--')\n",
    "\n",
    "def update(frame):\n",
    "    size = frames[frame]\n",
    "    model.fit(data[X_cols].iloc[:size], data[y_col].iloc[:size])\n",
    "    lne.set_data(data['timestep'], model.predict(data[X_cols]))\n",
    "    \n",
    "    bar.set_data([data['timestep'].iloc[:size].max(),]*2, ax.get_ylim())\n",
    "    return lne, bar\n",
    "    \n",
    "anim = FuncAnimation(fig, update, frames=len(frames), interval=100, blit=True)\n",
    "\n",
    "ax.set_yscale('symlog')\n",
    "ax.set_xlabel('Timestep', fontsize=18)\n",
    "ax.set_ylabel('Force ($E_H/a_B$)', fontsize=18)\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(8, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This video shows the changes in the fitness of the model as we add new training data. In each frame, the model is trained using all of the data to the left of the blue bar. The black line is the TD-DFT result and the red line in the ML prediction. Notice how the model first starts to accurately predict the stopping power in low-force region and then accurately models the high force regions. After we gather about half of the training data, our model predictions no longer fluctuate with adding more data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.save(os.path.join('figures', 'training-animation.mp4'), dpi=330, writer='ffmpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
